# -*- coding: utf-8 -*-
"""Data preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GJd3BcR_FnZ14OSkxi1sYxc_RZdxlCGk

# 1) Import packages and data
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt # data visualization
import seaborn as sns # statistical data visualization
# %matplotlib inline

import warnings

warnings.filterwarnings('ignore')

# get data from drive
from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/Colab Notebooks/

df = pd.read_csv('Cocoon_24032023.csv')

"""# 2) Simple processing on null and unnecessary data

1) Eliminate 'URL' column as I will not be needing it in the future
"""

df=df.drop(columns=['URL'])

"""2) Filter to eliminate null value in "Name". For sales data, later on, it will use filter code which is only aplicaple with nonnull data (step 4)"""

df = df.dropna(subset=['Name', 'Sales'])

df

# check if df reach needed non-null features and check for type of data for the next step
df.info()
df.isnull().sum()

"""# 3) Date"""

print(df.dtypes)

from datetime import datetime
df['New_date']=pd.to_datetime(df['Date'], format='%d/%m/%Y',errors = 'coerce')

df=df.drop(columns=['Date'])
df.columns = df.columns.str.replace('New_date', 'Date')

"""# 4) Sales

4.1) Remove "Da ban" part in "Sales" and  to make "Sales" in the same structure.
"""

da_ban_data = df[df['Sales'].str.startswith('Đã bán')]
non_da_ban_data = df[~df['Sales'].str.startswith('Đã bán')]

# remove "Đã bán" part from beginning of each string
da_ban_data['Sales'] = da_ban_data['Sales'].str.replace('Đã bán', '')

# merge filtered dataset back into original dataset
df = pd.concat([da_ban_data, non_da_ban_data], ignore_index=True)

"""4.2) turn "k" to thousands and change data type (to make "Sales" in the same type and structure)"""

# replace "k" with "000" in "Sales" column
df['Sales'] = df['Sales'].str.replace('k', '000')
# before change the data to numeric type as wish, the data that use comma such as "1,400" in sales must be change
# Remove comma from the string
df['Sales'] = df['Sales'].str.replace(',', '')

df = df.dropna(subset=['Sales'])

# there are data that is empty string as initially it can be "Da ban" with no sale number
# therefore, replace those with a valid value or remove the row entirely and change column type to numeric
df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce').fillna(0)
df = df.dropna(subset=['Sales'])

# print the names of the products with sales equal to 0
zero_sales = df[df["Sales"] == 0.0]
zero_sales.info()

"""# 5) Rating record

"""

#Perform "Rating record" same as "Sales"
# replace "k" with "000":
df['Rating record'] = df['Rating record'].str.replace('k', '000')
# before change the data to numeric type as wish, the data that use comma such as "1,400" in sales must be change
# Remove comma from the string
df['Rating record'] = df['Rating record'].str.replace(',', '')

# therefore, replace those with a valid value or remove the row entirely and change column type to numeric
df['Rating record'] = pd.to_numeric(df['Rating record'], errors='coerce').fillna(0)
df = df.dropna(subset=['Rating record'])

df

"""# 6) Price"""

# extract only the numeric part of the "Price" column
df["Price"] = df["Price"].str.extract(r"(\d+\.?\d*)").astype(float)

# extract only the numeric part of the "Discount" column
df["Discount"] = df["Discount"].str.extract(r"(\d+\.?\d*)").astype(float)
df.columns = df.columns.str.replace('Discount', 'Discount(%)')

"""# 7) Category and Product ID"""

# define a function to assign categories based on product names
def assign_category(name):
    if "cà phê" in name.lower():
        return "Coffee"
    elif "hoa hồng" in name.lower():
        return "Rose"
    elif "bưởi" in name.lower():
        return "Pomelo"
    elif "nghệ" in name.lower():
        return "Ginger"
    elif "bí đao" in name.lower():
        return "Squash"
    else:
        return "Other"

# define a function to assign categories based on product names
def assign_ini(name):
    if "cà phê" in name.lower():
        return "C"
    elif "hoa hồng" in name.lower():
        return "R"
    elif "bưởi" in name.lower():
        return "P"
    elif "nghệ" in name.lower():
        return "G"
    elif "bí đao" in name.lower():
        return "S"
    else:
        return "O"
# apply the function to create a new "category" column
df["Category"] = df["Name"].apply(lambda name: assign_category(name))
df["Ini_cat"] = df["Name"].apply(lambda name: assign_ini(name))

#create seperate dataset for each category
coffee_df = df[df["Category"] == "Coffee"]
rose_df = df[df["Category"] == "Rose"]
pomelo_df = df[df["Category"] == "Pomelo"]
ginger_df = df[df["Category"] == "Ginger"]
squash_df = df[df["Category"] == "Squash"]

# group by product name and assign a product ID to each category
coffee_df["Group_ID"] = coffee_df.groupby("Name").ngroup() + 1
rose_df["Group_ID"] = rose_df.groupby("Name").ngroup() + 1
pomelo_df["Group_ID"] = pomelo_df.groupby("Name").ngroup() + 1
ginger_df["Group_ID"] = ginger_df.groupby("Name").ngroup() + 1
squash_df["Group_ID"] = squash_df.groupby("Name").ngroup() + 1

# merge data with category type and ID back as official dataset 
df=pd.concat([coffee_df, rose_df, pomelo_df, ginger_df, squash_df], ignore_index=True)

# create Product_ID column based on category initial and category ID
df['Product_ID'] = df.apply(lambda row: str(row['Ini_cat']) + str(row['Group_ID']), axis=1)

print(df[df["Discount(%)"].notna()])

# Write the DataFrame to a CSV file
df.to_csv("Preprocessed_data.csv", index=True)
coffee_df.to_csv("Coffee_data.csv", index=True)
rose_df.to_csv("Rose_df.csv", index=True)
pomelo_df.to_csv("Pomelo_df.csv", index=True)
ginger_df.to_csv("Ginger_df.csv", index=True)
squash_df.to_csv("Squash_df.csv", index=True)

df